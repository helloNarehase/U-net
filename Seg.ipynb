{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 9715512528138228877\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 22385000448\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 15781667858747911575\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Dropout, concatenate, Conv2DTranspose, UpSampling2D, Normalization, LeakyReLU\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from splitImage import loadImages as loadImage\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160by160px\n",
      "Split Data Count :  1000\n"
     ]
    }
   ],
   "source": [
    "ColorMapping = {}\n",
    "\n",
    "path = \".\\\\cityscapes_data\\\\cityscapes_data\\\\train\"\n",
    "\n",
    "all_ = os.listdir(path)\n",
    "HIGH = [path+\"\\\\\"+i for i in all_]\n",
    "# print(HIGH)\n",
    "a = loadImage()\n",
    "a.set(all_[:1000])\n",
    "a.load(path)\n",
    "ap = a.split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.35576256  1.35576256 20.88045542 ...  1.35576256  1.35576256\n",
      "  1.35576256]\n",
      "[ 1.35576256 14.29647203 16.11871308 20.88045542 28.91801299 29.07365864\n",
      " 31.9066061  37.37814348 49.99652836 51.94508745]\n",
      "1.3557625567011442\n",
      "14.296472030268262\n",
      "16.118713080316095\n",
      "20.880455424130638\n",
      "28.918012991844037\n",
      "29.073658642749944\n",
      "31.906606096502312\n",
      "37.37814348373149\n",
      "49.9965283622329\n",
      "51.94508745179304\n"
     ]
    }
   ],
   "source": [
    "x = np.array(ap)[:,0]\n",
    "y = np.array(ap)[:,1]/10\n",
    "yShape = y.shape\n",
    "kmeans = KMeans(n_clusters=10)\n",
    "kmeans.fit(y.reshape(-1,3))\n",
    "# 클러스터 중심값\n",
    "cluster_centers = kmeans.cluster_centers_\n",
    "\n",
    "# 클러스터 할당\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# 클러스터 중심값으로 통일시킨 데이터\n",
    "data_uniform = np.sum(cluster_centers[labels], axis= 1)\n",
    "index = -1\n",
    "LableData = []\n",
    "DataShape = len(data_uniform)\n",
    "print(data_uniform)\n",
    "print(np.unique(data_uniform, axis=0))\n",
    "for i in (np.unique(data_uniform, axis=0)):\n",
    "    print(i)\n",
    "    if i in ColorMapping:\n",
    "        index = ColorMapping[i]\n",
    "    else:\n",
    "        index += 1\n",
    "        ColorMapping[i] = index\n",
    "    # LableData.append(index)\n",
    "# y = np.array(LableData).reshape(DataShape, 1)``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "LableDatas = {}\n",
    "for i,v in enumerate(np.unique(data_uniform, axis=0)):\n",
    "    LableDatas[str(v)] = i\n",
    "print(len(LableDatas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25600000\n",
      "(25600000,)\n"
     ]
    }
   ],
   "source": [
    "print(DataShape)\n",
    "print(data_uniform.shape)\n",
    "mans = np.zeros(DataShape)\n",
    "for i in range(DataShape):\n",
    "    mans[i] = LableDatas[str(data_uniform[i])]\n",
    "n,w,h,c = x.shape\n",
    "y = mans.reshape(n,w,h,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 160, 160, 3)\n",
      "(1000, 160, 160, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def unet():\n",
    "    inputs = Input((160, 160, 3))\n",
    "    \n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
    "    conv1 = Normalization()(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    pool1 = LeakyReLU()(pool1)\n",
    "    \n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    \n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    \n",
    "    conv4 = Conv2D(512, 3, activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation='relu', padding='same')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "    \n",
    "    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = Conv2DTranspose(256, 2, strides=(2, 2), padding='same', activation='relu')(drop5)\n",
    "    merge6 = concatenate([drop4, up6], axis=3)\n",
    "    conv6 = Conv2D(512, 3, activation='relu', padding='same')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation='relu', padding='same')(conv6)\n",
    "    \n",
    "    up7 = UpSampling2D(size=(2, 2))(conv6)\n",
    "    merge7 = concatenate([conv3, up7], axis=3)\n",
    "    conv7 = Conv2D(256, 3, activation='relu', padding='same')(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation='relu', padding='same')(conv7)\n",
    "    \n",
    "    up8 = UpSampling2D(size=(2, 2))(conv7)\n",
    "    merge8 = concatenate([conv2, up8], axis=3)\n",
    "    conv8 = Conv2D(128, 3, activation='relu', padding='same')(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation='relu', padding='same')(conv8)\n",
    "    \n",
    "    up9 = UpSampling2D(size=(2, 2))(conv8)\n",
    "    merge9 = concatenate([conv1, up9], axis=3)\n",
    "    conv9 = Conv2D(64, 3, activation='relu', padding='same')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation='relu', padding='same')(conv9)\n",
    "    \n",
    "    # conv10 = Conv2D(1, 1, activation='relu')(conv9)\n",
    "    conv10 = Conv2D(1, 1, activation='softmax')(conv9)\n",
    "    \n",
    "    model = Model(inputs=[inputs], outputs=[conv10])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = unet()\n",
    "model.compile(tf.optimizers.RMSprop(0.0001, clipvalue=1.0), loss= tf.losses.CategoricalCrossentropy(),metrics=[\"accuracy\"])\n",
    "# validation accuracy, validation loss\n",
    "history = model.fit(np.array(x),np.array(y),5, 500)    \n",
    "# with tf.device(\"GPU:0\"):\n",
    "#     history = model.fit(np.array(x),np.array(y),55, 500)\n",
    "model.save(\"kiki.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
